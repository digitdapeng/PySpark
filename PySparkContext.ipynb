{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "on colab\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q https://downloads.apache.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
    "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with pyspark.SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(appName=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.24\n",
      "Wall time: 3.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#sc = pyspark.SparkContext(appName=\"Pi\")\n",
    "num_samples = 100\n",
    "\n",
    "def inside(p):     \n",
    "  x, y = random.random(), random.random()\n",
    "  return x*x + y*y < 1\n",
    "\n",
    "count = sc.parallelize(range(0, num_samples)).filter(inside).count()\n",
    "\n",
    "pi = 4 * count / num_samples\n",
    "print(pi)\n",
    "\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD Transformation\n",
    "transfomation produce RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 1, 2, 3]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatMap\n",
    "rdd=sc.parallelize([2,3,4])\n",
    "y=rdd.flatMap(lambda x: range(1,x))\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map\n",
    "rdd=sc.parallelize([2,3,4])\n",
    "y=rdd.map(lambda x: x+1)\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter\n",
    "rdd=sc.parallelize([1,2,3,4,5,6,7])\n",
    "y=rdd.filter(lambda x: x%2==1)\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample\n",
    "rdd=sc.parallelize(range(5))\n",
    "y=rdd.sample(withReplacement=True,fraction=0.5)\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 14, 15, 16, 17, 18]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#union\n",
    "rdd1=sc.parallelize(range(9))\n",
    "rdd2=sc.parallelize(range(14,19))\n",
    "y=rdd1.union(rdd2)\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intersection\n",
    "rdd1=sc.parallelize(range(9))\n",
    "rdd2=sc.parallelize(range(4,19))\n",
    "y=rdd1.intersection(rdd2)\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 8, 16, 1, 9, 17, 2, 10, 18, 3, 11, 4, 12, 5, 13, 6, 14, 7, 15]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#distinct\n",
    "rdd1=sc.parallelize(range(9))\n",
    "rdd2=sc.parallelize(range(4,12))\n",
    "y=rdd1.union(rdd2).distinct()\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 8, 6, 6, 5, 4, 3, 2]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sortBy\n",
    "rdd1=sc.parallelize([5,6,8,3,2,6,9,4])\n",
    "rdd2=sc.parallelize(range(4,12))\n",
    "y=rdd1.sortBy(lambda x: x, ascending=False,numPartitions=None)\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 26), ('H', 10), ('Z', 1)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sortBy\n",
    "rdd1=sc.parallelize([(\"H\",10),(\"A\",26),(\"Z\",1)])\n",
    "y=rdd1.sortBy(lambda x: x[1], ascending=False,numPartitions=None)\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 7]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapPartitions\n",
    "rdd=sc.parallelize([1,2,3,4],2)\n",
    "def f(x): yield sum(x)\n",
    "y=rdd.mapPartitions(f)\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapPartitionsWithIndex\n",
    "rdd=sc.parallelize([1,2,3,4],3)\n",
    "def f(splitIndex, x): yield splitIndex\n",
    "y=rdd.mapPartitionsWithIndex(f)\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [3, 3]), (1, [1, 1, 4, 7]), (2, [2, 5])]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#groupBy\n",
    "rdd=sc.parallelize([1,1,3,5,7,3,2,4])\n",
    "res=rdd.groupBy(lambda x: x%3).collect()\n",
    "[(x, sorted(y)) for (x, y) in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 101), (2, 102), (3, 103), (4, 104)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zip\n",
    "rdd1=sc.parallelize(range(1,5))\n",
    "rdd2=sc.parallelize(range(101,105))\n",
    "y=rdd1.zip(rdd2)\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 0), ('b', 1), ('c', 2), ('d', 3)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zipWithIndex\n",
    "rdd1=sc.parallelize([\"a\",\"b\",\"c\",\"d\"])\n",
    "y=rdd1.zipWithIndex()\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [[0], [0]]),\n",
       " (1, [[1], [1]]),\n",
       " (2, [[], [2]]),\n",
       " (3, [[], [3]]),\n",
       " (4, [[2], [4]])]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keyBy and cogroup()\n",
    "x=sc.parallelize(range(0,3)).keyBy(lambda x: x*x)\n",
    "y=sc.parallelize(zip(range(5),range(6)))  #the extra list element is ignored in zip\n",
    "[(x,list(map(list,y))) for x,y in sorted(x.cogroup(y).collect())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2, 3], [4, 5], [6, 7]]\n",
      "[[1, 4, 5, 6, 7], [2, 3]]\n"
     ]
    }
   ],
   "source": [
    "#rePartition\n",
    "rdd=sc.parallelize([1,2,3,4,5,6,7],4)\n",
    "print(rdd.glom().collect())\n",
    "print(rdd.repartition(2).glom().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2, 3], [4, 5], [6, 7]]\n",
      "[[1, 2, 3], [4, 5, 6, 7]]\n"
     ]
    }
   ],
   "source": [
    "#coalesce\n",
    "rdd=sc.parallelize([1,2,3,4,5,6,7],4)\n",
    "print(rdd.glom().collect())\n",
    "print(rdd.coalesce(2).glom().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD Action\n",
    "Produce a value back to Spark driver program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#reduce\n",
    "rdd=sc.parallelize([1,2,3,4,5])\n",
    "print(rdd.reduce(add))\n",
    "\n",
    "print(sc.parallelize(range(10)).map(lambda x: 1).reduce(add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first\n",
    "rdd=sc.parallelize([2,3,4,5])\n",
    "rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#takeOrdered\n",
    "rdd=sc.parallelize([2,7,6,3,4,5])\n",
    "rdd.takeOrdered(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 7, 6, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take\n",
    "rdd=sc.parallelize([2,7,6,3,4,5])\n",
    "rdd.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count\n",
    "rdd=sc.parallelize([2,7,6,3,4,5])\n",
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 7, 6, 3, 4, 5]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collect\n",
    "rdd=sc.parallelize([2,7,6,3,4,5])\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saveAsTextFile\n",
    "rdd=sc.parallelize([2,7,6,3,4,5])\n",
    "#rdd.saveAsTextFile(\"data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#foreach\n",
    "def f(x): print(x)\n",
    "sc.parallelize([2,7,6,3,4,5]).foreach(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#foreachPartition\n",
    "def f(iter):\n",
    "    for x in iter:\n",
    "        print(x)\n",
    "sc.parallelize([2,7,6,3,4,5]).foreachPartition(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.86607004772212"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#min,max,mean,sum,variance,stdev\n",
    "rdd=sc.parallelize(range(100))\n",
    "rdd.stdev()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {2: 2, 4: 2, 6: 2, 3: 1, 5: 2, 7: 3, 3.5: 2})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#countByValue\n",
    "rdd=sc.parallelize([2,4,6,3,5,6,2,7,5,4,7,7,3.5,3.5])\n",
    "rdd.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'(6) PythonRDD[89] at RDD at PythonRDD.scala:53 []\\n |  MapPartitionsRDD[88] at mapPartitions at PythonRDD.scala:133 []\\n |  ShuffledRDD[87] at partitionBy at <unknown>:0 []\\n +-(6) PairwiseRDD[86] at subtract at <ipython-input-38-39c0a860c938>:4 []\\n    |  PythonRDD[85] at subtract at <ipython-input-38-39c0a860c938>:4 []\\n    |  UnionRDD[84] at union at <unknown>:0 []\\n    |  PythonRDD[82] at RDD at PythonRDD.scala:53 []\\n    |  ParallelCollectionRDD[81] at parallelize at PythonRDD.scala:195 []\\n    |  PythonRDD[83] at RDD at PythonRDD.scala:53 []\\n    |  ParallelCollectionRDD[80] at parallelize at PythonRDD.scala:195 []'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#toDebugString\n",
    "rdd1=sc.parallelize(range(1,9),3)\n",
    "rdd2=sc.parallelize(range(21,29),3)\n",
    "rdd=rdd2.subtract(rdd1)\n",
    "rdd.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a1', ['b1', 'c1', 'd1']), ('a2', ['b2', 'c2', 'd2'])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create paired RDDs\n",
    "rdd=sc.parallelize([(\"a1\",\"b1\",\"c1\",\"d1\"),(\"a2\",\"b2\",\"c2\",\"d2\")])\n",
    "rdd.map(lambda x: (x[0],list(x[1:]))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformation on paired RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduceByKey, groupByKey, mapValues,flatMapValues, keys, sortByKey, subtractByKey, \n",
    "# join, rightOuterJoin,leftOuterJoin, cogroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdd Lineage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 'is')\n",
      "(2, 'pyspark')\n",
      "(1, 'line')\n",
      "(1, 'spark')\n",
      "(1, 'with')\n",
      "(1, 'python,')\n",
      "(1, 'great!')\n",
      "(1, 'fun.')\n",
      "(1, '2')\n"
     ]
    }
   ],
   "source": [
    "rdd=sc.textFile(\"pytest.txt\")\n",
    "nonempty_line=rdd.filter(lambda x: len(x)>0)\n",
    "words=nonempty_line.flatMap(lambda x: x.split(' '))\n",
    "y=words.map(lambda x: (x,1))\n",
    "word_count=y.reduceByKey(add).map(lambda x: (x[1],x[0])).sortByKey(False)\n",
    "for word in word_count.collect():\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with pyspark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark create RDD example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Advertising.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, TV: double, Radio: double, Newspaper: double, Sales: double]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv(path=path,\n",
    "                    sep=',',encoding='UTF-8',comment=None,\n",
    "                    header=True,inferSchema=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+---------+-----+\n",
      "|_c0|   TV|Radio|Newspaper|Sales|\n",
      "+---+-----+-----+---------+-----+\n",
      "|  1|230.1| 37.8|     69.2| 22.1|\n",
      "|  2| 44.5| 39.3|     45.1| 10.4|\n",
      "|  3| 17.2| 45.9|     69.3|  9.3|\n",
      "|  4|151.5| 41.3|     58.5| 18.5|\n",
      "|  5|180.8| 10.8|     58.4| 12.9|\n",
      "+---+-----+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- TV: double (nullable = true)\n",
      " |-- Radio: double (nullable = true)\n",
      " |-- Newspaper: double (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://dwang-lt10.ostendo.local:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>rdd</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=rdd>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
