{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "The audited results summary audited_results.xlsx was located at:\n",
      "output/Audited\n",
      "Generate data set summary took = 21.507484912872314 s\n",
      "================================================================\n",
      "Collecting data types.... Please be patient!\n",
      "Generate counts took = 0.0019941329956054688 s\n",
      "================================================================\n",
      "Collecting features' counts.... Please be patient!\n",
      "Generate counts took = 1.5299100875854492 s\n",
      "================================================================\n",
      "Collecting data frame description.... Please be patient!\n",
      "Generate data frame description took = 0.31217002868652344 s\n",
      "================================================================\n",
      "Calculating percentiles.... Please be patient!\n",
      "Generate percentiles took = 0.6043846607208252 s\n",
      "================================================================\n",
      "Calculating features' length.... Please be patient!\n",
      "Generate features' length took = 0.759965181350708 s\n",
      "================================================================\n",
      "Calculating top 5 frequent items.... Please be patient!\n",
      "Generate rates took: 1.118011474609375 s\n",
      "================================================================\n",
      "Calculating rates.... Please be patient!\n",
      "Generate rates took: 2.474384069442749 s\n",
      "Auditing numerical data took = 6.844695329666138 s\n",
      "================================================================\n",
      "Collecting data types.... Please be patient!\n",
      "Generate counts took = 0.001992940902709961 s\n",
      "================================================================\n",
      "Collecting features' counts.... Please be patient!\n",
      "Generate counts took = 14.064389944076538 s\n",
      "================================================================\n",
      "Calculating features' length.... Please be patient!\n",
      "Generate features' length took = 1.5727932453155518 s\n",
      "================================================================\n",
      "Calculating top 5 frequent items.... Please be patient!\n",
      "Generate rates took: 7.007259368896484 s\n",
      "================================================================\n",
      "Calculating rates.... Please be patient!\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3f6fac5be7be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# auditing in one function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mauditing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PySparkAudit\\PySparkAudit.py\u001b[0m in \u001b[0;36mauditing\u001b[1;34m(df_in, writer, columns, deciles, top_freq_item, bins, top_cat_item, method, output_dir, types, d_time, rotation, sample_size, display, tracking)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[0mnum_summary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcat_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m         \u001b[0mcat_summary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcategory_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtop_freq_item\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtracking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m         \u001b[0mcat_summary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Category_summary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PySparkAudit\\PySparkAudit.py\u001b[0m in \u001b[0;36mcategory_summary\u001b[1;34m(df_in, columns, top_n, tracking)\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[0mf_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtracking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[0mfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfreq_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtop_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtracking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m         \u001b[0mrate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtracking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mdata_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0md_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PySparkAudit\\PySparkAudit.py\u001b[0m in \u001b[0;36mrates\u001b[1;34m(df_in, columns, numeric, tracking)\u001b[0m\n\u001b[0;32m    297\u001b[0m           \u001b[0mrate_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m           rate_variance.append(data.na.drop(subset=[c]).select(c).distinct().count() /\n\u001b[1;32m--> 299\u001b[1;33m                                data.na.drop(subset=[c]).select(c).count())) for c in data.columns]\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         d = {'feature': columns, 'feature_variance': rate_variance, 'rate_null': rate_null,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PySparkAudit\\PySparkAudit.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    297\u001b[0m           \u001b[0mrate_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m           rate_variance.append(data.na.drop(subset=[c]).select(c).distinct().count() /\n\u001b[1;32m--> 299\u001b[1;33m                                data.na.drop(subset=[c]).select(c).count())) for c in data.columns]\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         d = {'feature': columns, 'feature_variance': rate_variance, 'rate_null': rate_null,\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark regression example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# from PySparkAudit import dtypes_class, hist_plot, bar_plot, freq_items,feature_len\n",
    "# from PySparkAudit import dataset_summary, rates, trend_plot\n",
    "\n",
    "# Audited results output path\n",
    "out_path = 'output'\n",
    "\n",
    "# import PySpark Audit function\n",
    "from PySparkAudit import auditing\n",
    "\n",
    "# load dataset\n",
    "# Spanish High Speed Rail tickets pricing - Renfe (~2.58M)\n",
    "# https://www.kaggle.com/thegurus/spanish-high-speed-rail-system-ticket-pricing\n",
    "\n",
    "data = spark.read.csv(path='data/high_speed_spanish_trains.csv',\n",
    "                      sep=',', encoding='UTF-8', comment=None, header=True, inferSchema=True)\n",
    "\n",
    "# auditing in one function\n",
    "auditing(data, output_dir=out_path, tracking=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
